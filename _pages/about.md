---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**


<!-- MindShift: CHI 2024 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CHI 2024</div><img src='images/mindshift.jpg' alt="MindShift" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention](https://doi.org/10.1145/3613904.3642790)

**R. Wu**, C. Yu, X. Pan, Y. Liu, **N. Zhang**, Y. Fu, Y. Wang, Z. Zheng, L. Chen, Q. Jiang, X. Xu, Y. Shi

[**Project**](#) <strong><span class='show_paper_citations' data='chi2024-mindshift'></span></strong>
- paper content
</div>
</div>

- [Project Link](https://github.com), R. Wu, C. Yu, X. Pan, **CHI 2024**

<!-- ORBO: HRI 2024 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">HRI 2024</div><img src='images/orbo.jpg' alt="ORBO" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ORBO: The Emotionally Intelligent Anthropomorphic Robot Enhancing Smartphone Interaction](https://doi.org/10.1145/3610978.3640695)

**N. Zhang**, Z. Chi, Z. Xu, Q. Chen, V. Campo, Y. Guo, H. Mi

[**Project**](#) <strong><span class='show_paper_citations' data='hri2024-orbo'></span></strong>
- paper content
</div>
</div>

- [Project Link](https://github.com), **N. Zhang**, Z. Chi, Z. Xu, **HRI 2024**

<!-- Eye See You: HRI 2024 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">HRI 2024</div><img src='images/eye-see-you.jpg' alt="Eye See You" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Eye See You: The Emotionally Intelligent Anthropomorphic Robot Enhancing Smartphone Interaction](https://doi.org/10.1145/3610978.3641267)

**Z. Xu**, Z. Chi, **N. Zhang**, V. Campo, Q. Chen

[**Project**](#) <strong><span class='show_paper_citations' data='hri2024-eyesee'></span></strong>
- paper content
</div>
</div>

- [Project Link](https://github.com), **Z. Xu**, Z. Chi, **N. Zhang**, **HRI 2024**

<!-- AI-generated Image Tools: CSCW 2024 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CSCW 2024</div><img src='images/ai-image-tools.jpg' alt="AI Image Tools" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Exploring the Impact of AI-generated Image Tools on Professional and Non-professional Users in the Art and Design Fields](https://doi.org/10.1145/3678884.3681890)

**Y. Tang**, **N. Zhang**, M. Ciancia, Z. Wang

[**Project**](#) <strong><span class='show_paper_citations' data='cscw2024-aiimages'></span></strong>
- paper content
</div>
</div>

- [Project Link](https://github.com), **Y. Tang**, **N. Zhang**, M. Ciancia, **CSCW 2024**

# üéñ Honors and Awards
- *2024.11*, Comprehensive Excellence Scholarship, Tsinghua University
- *2023.01*, Asia-Pacific Youth Leadership Award (APEA)
- *2022.06*, Outstanding Graduate and Excellent Thesis Award, School of Journalism and Communication, Tsinghua University
- *2022.06*, Contribution Award, Xinya College, Tsinghua University
- *2021.11*, Toyota Scholarship for Comprehensive Excellence, Tsinghua University
- *2020.10*, Academic Excellence Scholarship, Tsinghua University
- *2019.10*, Outstanding Social Work Scholarship, Tsinghua University
- *2019.10*, Social Practice Excellence Scholarship, Tsinghua University
- *2019.10*, Volunteer Service Excellence Scholarship, Tsinghua University

# üìñ Educations
- *2022.09 - 2026.06 (Expected)*, Tsinghua University, Master's in Information Art and Design (Interdisciplinary)
- *2018.09 - 2022.06*, Tsinghua University, Dual Bachelor's Degrees: Journalism & English (Xinya College)
  
# üíª Professional Experience
- *2022.03 - Present*, Independent Content Creator
  652K+ on [Rednote](https://www.xiaohongshu.com/user/profile/5b25a6c7e8ac2b7b77f724f2) | 960K+ on [TikTok](https://www.douyin.com/user/your_actual_id) | 309K+ on [Bilibili](https://space.bilibili.com/93662579)
- *2024.04 - 2024.08*, Product Manager Intern ‚Äî Meituan AI Evaluation Function Project
- *2021.08 - 2022.01*, Organization Culture Intern ‚Äî ByteDance
- *2021.01 - 2021.03*, Content Planner Intern ‚Äî NetEase Media

# üì∑ Hobbies
- I am passionate about the arts, and find inspiration in dancing, singing, photography, and painting.


